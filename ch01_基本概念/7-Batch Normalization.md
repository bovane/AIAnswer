[TOC]

# Batch Normalization

Batch Normalization 是 Sergey Ioffe 和 Christian Szegedy于2015年提出的一种加速神经网络训练的方法。[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](http://noahsnail.com/2017/09/04/2017-09-04-Batch%20Normalization%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E2%80%94%E2%80%94%E4%B8%AD%E8%8B%B1%E6%96%87%E5%AF%B9%E7%85%A7/) 该论文首次提出Batch Normalization方法，众所周知训练神经网络的复杂性在于每层输入的分布在训练过程中会发生变化，而==机器学习领域有一个非常重要的假设：独立同分布假设(IID)，就是假设训练数据和测试数据是满足相同分布的，这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。== **BatchNorm的核心思想——就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布**，这样从而加速神经网络训练。　为什么深度神经网络**随着网络深度加深，训练起来越困难，收敛越来越慢？**这是个在DL领域很接近本质的问题，很多论文都是解决这个问题的，比如ReLU激活函数，再比如Residual Network，BN本质上也是解释并从某个不同的角度来解决这个问题的。

## 什么是Internal Covariate Shift？

Internal Covariate Shift 叫做内部协变量转移，**该现象指在神经网络训练过程中：**每层输入的分布在训练过程中会发生变化，因为前面的层的参数会发生变化。通过要求较低的学习率和仔细的参数初始化减慢了训练，**并且使具有饱和非线性的模型训练起来非常困难。** 换句话说**如果ML系统实例集合<X,Y>中的输入值X的分布老是变，这不符合IID假设**，网络模型很难**稳定的学规律**。 对于神经网络这种包含很多隐层的结构，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临covariate shift的问题，也就是**在训练过程中，隐层的输入分布老是变来变去，这就是所谓的“Internal Covariate Shift”，Internal指的是深层网络的隐层，是发生在网络内部的事情，而不是covariate shift问题只发生在输入层。**在输入层的covariate shift 能够通过一半的Normalization解决。鉴于隐藏层的Covariate Shift，BN方法的思路便是对每一个隐藏层进行Normalization。==下面通过实例说明一下，隐藏层的激活分布输入的问题。==

下图说明了数据分布对训练会产生影响.如果使用 像 tanh 的激励函数, Wx 的激活值就变成了 ~0.1 和 ~1, **接近于 1 的部已经处在了 激励函数的饱和阶段, 也就是如果 x 无论再怎么扩大**, tanh 激励函数输出值也还是 接近1. 换句话说, 神经网络在初始阶段已经不对那些比较大的 x 特征范围 敏感了. 这==样很糟糕, 想象我轻轻拍自己的感觉和重重打自己的感觉居然没什么差别, 这就证明我的感官系统失效了.== 当然输入层，我们可以通过一般的标准化来解决这个问题。但是对于隐藏层，我们无法用一般的标准化方法。

![](https://raw.githubusercontent.com/bovane/md_images/master/20190327213427.png)

![preview](https://pic2.zhimg.com/v2-2b4d8694d6e6c6f42ecbaee95ae40eed_r.jpg)

因此自然而然就有BatchNorm的基本思想：能不能**让每个隐层节点的激活输入分布固定下来呢**？这样就避免了“Internal Covariate Shift”问题了。

## Batch Normalization 的实践依据

BN不是凭空拍脑袋拍出来的好点子，它是有启发来源的：之前的研究表明如果在图像处理中对输入图像进行白化（Whiten）操作的话——所谓**白化**，**就是对输入数据分布变换到0均值，单位方差的正态分布**——==那么神经网络会较快收敛==，那么BN作者就开始推论了：图像是深度神经网络的输入层，做白化能加快收敛，那么其实对于深度网络来说，其中某个隐层的神经元是下一层的输入，意思是其实深度神经网络的每一个隐层都是输入层，不过是相对下一层来说而已，==那么能不能对每个隐层都做白化呢？这就是启发BN产生的原初想法==，而BN也确实就是这么做的，**可以理解为对深层神经网络每个隐层神经元的激活值做简化版本的白化操作。**

## BN的作用

- 加速神经网络训练过程：由于标准化的输入特征会加速学习，因此自然而然想到对隐层进行Normalization也会加快学习
- 解决内部协变量转移问题
- 轻微的正则化效果

## BN的实质

BN的基本思想其实相当直观：因为深层神经网络在做非线性变换前的<font color=red>**激活输入值**</font>（就是那个x=WU+B，U是输入）**随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，==之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近==**（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这**导致反向传播时低层神经网络的梯度消失**，这是训练深层神经网络收敛越来越慢的**本质原因**，**而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布**，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是**这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。** 其实一句话就是：**对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。**因为梯度一直都能保持比较大的状态，所以很明显对神经网络的参数调整效率比较高，就是变动大，就是说向损失函数最优值迈动的步子大，也就是说收敛地快。BN说到底就是这么个机制，方法很简单，道理很深刻。**我们能保证非线性输入的分布在网络训练时保持更稳定，那么优化器将不太可能陷入饱和状态，训练将加速。** 批标准化减少了梯度对参数或它们的初始值尺度上的依赖，对通过网络的梯度流动有有益的影响。==这允许我们使用更高的学习率而没有发散的风险==。此外，批标准化使模型正则化并减少了对Dropout(Srivastava et al., 2014)的需求。最后，批标准化通过阻止网络陷入饱和模式让使用饱和非线性成为可能。

==但是这样会导致一个疑问==，如果都通过BN，那么不就跟把非线性函数替换成线性函数效果相同了？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的**表达能力**下降了，这也意味着深度的意义就没有了。**所以BN为了保证非线性的获得，对变换后的满足均值为0方差为1的x又进行了scale加上shift操作(y=scale\*x+shift)**，每个神经元增加了两个参数scale和shift参数，这两个参数是通过训练学习到的，==意思是通过scale和shift把这个值从标准正态分布左移或者右移一点并长胖一点或者变瘦一点，每个实例挪动的程度不一样，这样等价于非线性函数的值从正中心周围的线性区往非线性区动了动。==核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢。 <font color=red>但是很明显这里的scale和shift操作是会有争议的，因为按照论文作者论文里写的理想状态，就会又通过scale和shift操作把变换后的x调整回未变换的状态，</font>那不是饶了一圈又绕回去原始的“Internal Covariate Shift”问题里去了吗?

## 训练阶段如何做BatchNorm?

假设对于一个深层神经网络来说，其中两层结构如下：![](https://raw.githubusercontent.com/bovane/md_images/master/20190327215721.png)

要对每个隐层神经元的激活值做BN，可以想象成每个隐层又加上了一层BN操作层，它位于X=WU+B激活值获得之后，非线性函数变换之前，其图示如下：

![](https://raw.githubusercontent.com/bovane/md_images/master/20190327215945.png)

在论文中也提到，使得标准化成为模型框架的一部分。![](https://raw.githubusercontent.com/bovane/md_images/master/20190327220254.png)

为什么小批次训练比单个训练效果好？首先，小批量数据的梯度损失是训练集上的梯度估计，其质量随着批量增加而改善。第二，由于现代计算平台提供的并行性，对一个批次的计算比单个样本计算m次效率更高。

## BN 推理

在推理（inference）的过程中，很明显输入就只有一个实例，看不到Mini-Batch其它实例，那么这时候怎么对输入做BN呢？因为很明显一个实例是没法算实例集合求出的均值和方差的。这可如何是好？**然而没有从Mini-Batch数据里可以得到的统计量，那就想其它办法来获得这个统计量，就是均值和方差。**可以用从所有训练实例中获得的统计量来代替Mini-Batch里面m个训练实例获得的均值和方差统计量，因为本来就打算用全局的统计量，只是因为计算量等太大所以才会用Mini-Batch这种简化方式的，==那么在推理的时候直接用全局统计量即可==。

　　决定了获得统计量的数据范围，那么接下来的问题是如何获得均值和方差的问题。很简单，因为每次做Mini-Batch训练时，都会有那个Mini-Batch里m个训练实例获得的均值和方差，==现在要全局统计量，只要把每个Mini-Batch的均值和方差统计量记住，然后对这些均值和方差求其对应的数学期望即可得出全局统计量==

## BN 算法流程

![](https://raw.githubusercontent.com/bovane/md_images/master/20190328221938.png)

![](https://raw.githubusercontent.com/bovane/md_images/master/20190327224750.png)

算法1是通过MiNi-batch进行标准化，在一个mini-batch上进行标准化时大致分为四步：

- 计算mini-batch的均值
- 计算mini-batch的方差
- 标准化输入$x_{i}$ $\to x_{i}^{`}$ 
- 缩放和移动算法2是训练经过BN处理的网络。

该算法的输出为$y_{i}$,在训练过程中会学习$\beta$和$\gamma$两个超参数

算法2是BN Network网络的训练过程， 训练BN Network大致可以分为5步：

- 指定激活子集，向每一个激活中插入BN变换
- 训练$N_{BN}^{tr}$优化参数$\theta \cup {\gamma^{(k)},\beta^{(k)}}_{k=1}^{K}$
- 推理BN Network with 固定参数
- 对选定的激活子集，处理多个training mini-batch，最后平均他们，得到$E[x]\leftarrow E_{\beta}[u_{\beta}]$ 和$Var[x]\leftarrow \frac{m}{m-1}E_{\beta}[\sigma_{\beta}^{2}]$
- 在$N_{BN}^{inf}$ 中转换$y$ 

**BN效果：** 

![](https://raw.githubusercontent.com/bovane/md_images/master/20190328222043.png)

## BN demo实现

[demo](https://blog.csdn.net/shuzfan/article/details/79054561)

[Tensorflow BN](https://www.jianshu.com/p/2a95592d8489)

[BN前向传播过程和后向传播过程](https://zhuanlan.zhihu.com/p/26138673)

## 参考文献

[BN理解](https://zhuanlan.zhihu.com/p/24810318)

[什么是BN](https://www.cnblogs.com/guoyaohua/p/8724433.html)